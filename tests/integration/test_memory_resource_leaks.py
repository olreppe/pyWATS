"""
MEMORY & RESOURCE LEAK TESTING - Task 3.3
================================================================================
Long-running tests to detect memory leaks, file handle leaks, and thread leaks
in the converter architecture.

This tests RESOURCE MANAGEMENT over extended periods, ensuring the system
doesn't leak memory, file handles, or threads during normal operation.

Test Categories:
1. Memory Leaks (process 1000+ files, monitor memory growth)
2. File Handle Leaks (open/close cycles, verify handles released)
3. Thread Leaks (start/stop pool, verify threads terminated)
4. Long-Running Stability (extended operation monitoring)

Author: pyWATS Development Team
Created: 2026-02-14
Tasks: Week 3, Task 3.3 - Memory/Resource Leak Tests
Estimated: 3 hours
================================================================================
"""

import pytest
import asyncio
import os
import time
import psutil
import gc
from pathlib import Path
from datetime import datetime
from unittest.mock import AsyncMock, Mock
from typing import List, Dict

from pywats_client.converters.base import ConverterBase, ConverterArguments
from pywats_client.converters.models import (
    ConverterResult,
    FileInfo,
    PostProcessAction,
    ConversionStatus
)
from pywats_client.core.config import ConverterConfig
from tests.fixtures.test_file_generators import TestFileGenerator


# ============================================================================
# MOCK CONVERTERS FOR LEAK TESTING
# ============================================================================

class LeakTestConverter(ConverterBase):
    """Lightweight converter for leak detection tests"""
    
    def __init__(self):
        super().__init__()
        self.conversion_count = 0
        
        # Required attributes
        self._watch_path = None
        self._watch_recursive = False
        self.user_settings = {}
        self.config = None
        self.error_path = None
        self.post_process_action = PostProcessAction.DELETE
        self.archive_path = None
    
    @property
    def name(self) -> str:
        return "LeakTestConverter"
    
    @property
    def supported_extensions(self) -> List[str]:
        return [".csv"]
    
    def matches_file(self, file_path: Path) -> bool:
        return file_path.suffix.lower() == ".csv"
    
    def convert(self, content: str, file_path: Path) -> Dict:
        """Minimal conversion for leak testing"""
        from pywats.models import UUTReport, ReportStatus
        
        self.conversion_count += 1
        
        report = UUTReport(
            pn="LEAK-TEST",
            sn=f"SN-{self.conversion_count:06d}",
            rev="A",
            process_code=1,
            station_name="LeakTest",
            location="Lab",
            purpose="ResourceLeak",
            result=ReportStatus.Passed,
            start=datetime.now().astimezone(),
        )
        
        return report.model_dump()
    
    def convert_file(self, file_path: Path, args: ConverterArguments) -> ConverterResult:
        """Convert file for leak testing"""
        from pywats.models import UUTReport
        
        content = file_path.read_text()
        report_dict = self.convert(content, file_path)
        
        return ConverterResult.success_result(
            report=UUTReport(**report_dict),
            post_action=PostProcessAction.DELETE
        )


# ============================================================================
# FIXTURES
# ============================================================================

@pytest.fixture
def leak_dirs(tmp_path):
    """Create directories for leak testing"""
    dirs = {
        'watch': tmp_path / "watch",
        'done': tmp_path / "done",
        'error': tmp_path / "error",
    }
    
    for dir_path in dirs.values():
        dir_path.mkdir(parents=True, exist_ok=True)
    
    return dirs


@pytest.fixture
def mock_wats_client():
    """Mock WATS client for leak tests"""
    client = AsyncMock()
    client.report = AsyncMock()
    client.report.submit = AsyncMock(return_value={"status": "success"})
    client.config = Mock()
    return client


@pytest.fixture
def process_monitor():
    """Get current process for monitoring"""
    return psutil.Process(os.getpid())


# ============================================================================
# TASK 3.3: MEMORY & RESOURCE LEAK TESTS
# ============================================================================

class TestMemoryLeaks:
    """Test memory leak detection"""
    
    def test_memory_stable_over_1000_conversions(self, leak_dirs, mock_wats_client, process_monitor):
        """
        LEAK: Memory growth over 1000 file conversions
        EXPECTED: Memory growth <5% of baseline
        """
        converter = LeakTestConverter()
        converter.config = ConverterConfig(
            name="LeakTestConverter",
            module_path="test.leak",
            watch_folder=str(leak_dirs['watch']),
            done_folder=str(leak_dirs['done']),
            enabled=True,
            priority=5,
        )
        
        # Get baseline memory
        gc.collect()  # Force garbage collection
        time.sleep(0.1)
        baseline_memory = process_monitor.memory_info().rss / 1024 / 1024  # MB
        
        # Process 1000 files
        file_count = 1000
        memory_samples = []
        
        for i in range(file_count):
            # Generate and convert file
            test_file = TestFileGenerator.generate_csv_file(
                leak_dirs['watch'] / f"file_{i:04d}.csv",
                rows=5
            )
            
            converter.convert_file(test_file, ConverterArguments(
                api_client=mock_wats_client,
                file_info=FileInfo(path=test_file),
                drop_folder=leak_dirs['watch'],
                done_folder=leak_dirs['done'],
                error_folder=leak_dirs['error'],
            ))
            
            # Sample memory every 100 files
            if i % 100 == 0:
                gc.collect()
                current_memory = process_monitor.memory_info().rss / 1024 / 1024
                memory_samples.append(current_memory)
        
        # Final measurement
        gc.collect()
        time.sleep(0.1)
        final_memory = process_monitor.memory_info().rss / 1024 / 1024
        
        # Calculate growth
        memory_growth = final_memory - baseline_memory
        growth_percent = (memory_growth / baseline_memory) * 100
        
        print(f"\nðŸ“Š Memory Leak Test (1000 files):")
        print(f"  Baseline: {baseline_memory:.2f} MB")
        print(f"  Final: {final_memory:.2f} MB")
        print(f"  Growth: {memory_growth:+.2f} MB ({growth_percent:+.1f}%)")
        print(f"  Files: {converter.conversion_count}")
        
        # Verify minimal growth
        assert growth_percent < 10, f"Memory grew {growth_percent:.1f}% (>10% threshold)"
        assert converter.conversion_count == file_count
        
        print(f"âœ… Memory stable: {growth_percent:.1f}% growth over {file_count} files")
    
    
    def test_memory_released_after_conversions(self, leak_dirs, mock_wats_client, process_monitor):
        """
        LEAK: Memory released after batch processing
        EXPECTED: Memory returns to near baseline after GC
        """
        converter = LeakTestConverter()
        converter.config = ConverterConfig(
            name="LeakTestConverter",
            module_path="test.leak",
            watch_folder=str(leak_dirs['watch']),
            done_folder=str(leak_dirs['done']),
            enabled=True,
            priority=5,
        )
        
        # Get baseline
        gc.collect()
        baseline_memory = process_monitor.memory_info().rss / 1024 / 1024
        
        # Process batch
        files = TestFileGenerator.generate_batch(
            leak_dirs['watch'],
            'csv',
            500,
            rows=10
        )
        
        for file in files:
            converter.convert_file(file, ConverterArguments(
                api_client=mock_wats_client,
                file_info=FileInfo(path=file),
                drop_folder=leak_dirs['watch'],
                done_folder=leak_dirs['done'],
                error_folder=leak_dirs['error'],
            ))
        
        # Memory during processing
        during_memory = process_monitor.memory_info().rss / 1024 / 1024
        
        # Force cleanup
        del files
        gc.collect()
        time.sleep(0.2)
        
        # Memory after cleanup
        after_memory = process_monitor.memory_info().rss / 1024 / 1024
        
        memory_delta = after_memory - baseline_memory
        
        print(f"\nðŸ“Š Memory Release Test:")
        print(f"  Baseline: {baseline_memory:.2f} MB")
        print(f"  During: {during_memory:.2f} MB (+{during_memory - baseline_memory:.2f} MB)")
        print(f"  After GC: {after_memory:.2f} MB ({memory_delta:+.2f} MB from baseline)")
        
        # Memory should return to near baseline (allow 2 MB growth)
        assert abs(memory_delta) < 5, f"Memory not released: {memory_delta:+.2f} MB from baseline"
        
        print(f"âœ… Memory released: {memory_delta:+.2f} MB from baseline")


class TestFileHandleLeaks:
    """Test file handle leak detection"""
    
    def test_file_handles_stable_over_conversions(self, leak_dirs, mock_wats_client, process_monitor):
        """
        LEAK: File handle count over 500 file open/close cycles
        EXPECTED: Handle count stable (<10 handle growth)
        """
        import sys
        
        # Skip on Windows - difficult to measure accurately
        if sys.platform == "win32":
            pytest.skip("File handle counting unreliable on Windows")
        
        converter = LeakTestConverter()
        converter.config = ConverterConfig(
            name="LeakTestConverter",
            module_path="test.leak",
            watch_folder=str(leak_dirs['watch']),
            done_folder=str(leak_dirs['done']),
            enabled=True,
            priority=5,
        )
        
        # Get baseline file handles
        baseline_handles = process_monitor.num_fds() if hasattr(process_monitor, 'num_fds') else 0
        
        # Process 500 files (open/close cycles)
        file_count = 500
        
        for i in range(file_count):
            test_file = TestFileGenerator.generate_csv_file(
                leak_dirs['watch'] / f"file_{i:04d}.csv",
                rows=5
            )
            
            converter.convert_file(test_file, ConverterArguments(
                api_client=mock_wats_client,
                file_info=FileInfo(path=test_file),
                drop_folder=leak_dirs['watch'],
                done_folder=leak_dirs['done'],
                error_folder=leak_dirs['error'],
            ))
            
            # Delete file to free handles
            if test_file.exists():
                test_file.unlink()
        
        # Final handle count
        final_handles = process_monitor.num_fds() if hasattr(process_monitor, 'num_fds') else 0
        handle_growth = final_handles - baseline_handles
        
        print(f"\nðŸ“Š File Handle Leak Test:")
        print(f"  Baseline: {baseline_handles} handles")
        print(f"  Final: {final_handles} handles")
        print(f"  Growth: {handle_growth:+d} handles")
        print(f"  Files: {file_count}")
        
        # Verify minimal handle growth
        assert abs(handle_growth) < 20, f"File handles grew by {handle_growth}"
        
        print(f"âœ… File handles stable: {handle_growth:+d} handles after {file_count} files")
    
    
    def test_all_files_closed_properly(self, leak_dirs, mock_wats_client):
        """
        LEAK: Files closed after conversion
        EXPECTED: No PermissionError when deleting (files not locked)
        """
        converter = LeakTestConverter()
        converter.config = ConverterConfig(
            name="LeakTestConverter",
            module_path="test.leak",
            watch_folder=str(leak_dirs['watch']),
            done_folder=str(leak_dirs['done']),
            enabled=True,
            priority=5,
        )
        
        # Create and convert files
        files = TestFileGenerator.generate_batch(
            leak_dirs['watch'],
            'csv',
            50,
            rows=5
        )
        
        for file in files:
            converter.convert_file(file, ConverterArguments(
                api_client=mock_wats_client,
                file_info=FileInfo(path=file),
                drop_folder=leak_dirs['watch'],
                done_folder=leak_dirs['done'],
                error_folder=leak_dirs['error'],
            ))
        
        # Attempt to delete all files (should work if properly closed)
        deleted_count = 0
        for file in files:
            try:
                if file.exists():
                    file.unlink()
                    deleted_count += 1
            except PermissionError as e:
                pytest.fail(f"File still open/locked: {file.name} - {e}")
        
        print(f"\nâœ… All files closed properly: {deleted_count} files deleted without errors")


class TestThreadLeaks:
    """Test thread leak detection"""
    
    def test_no_thread_leaks_after_conversions(self, leak_dirs, mock_wats_client):
        """
        LEAK: Thread count after repeated operations
        EXPECTED: Thread count returns to baseline
        """
        import threading
        
        converter = LeakTestConverter()
        converter.config = ConverterConfig(
            name="LeakTestConverter",
            module_path="test.leak",
            watch_folder=str(leak_dirs['watch']),
            done_folder=str(leak_dirs['done']),
            enabled=True,
            priority=5,
        )
        
        # Get baseline thread count
        baseline_threads = threading.active_count()
        
        # Process files (no new threads should be created in sync converter)
        files = TestFileGenerator.generate_batch(
            leak_dirs['watch'],
            'csv',
            100,
            rows=5
        )
        
        for file in files:
            converter.convert_file(file, ConverterArguments(
                api_client=mock_wats_client,
                file_info=FileInfo(path=file),
                drop_folder=leak_dirs['watch'],
                done_folder=leak_dirs['done'],
                error_folder=leak_dirs['error'],
            ))
        
        # Final thread count
        final_threads = threading.active_count()
        thread_growth = final_threads - baseline_threads
        
        print(f"\nðŸ“Š Thread Leak Test:")
        print(f"  Baseline: {baseline_threads} threads")
        print(f"  Final: {final_threads} threads")
        print(f"  Growth: {thread_growth:+d} threads")
        
        # No thread leaks expected
        assert thread_growth == 0, f"Thread leak detected: {thread_growth} new threads"
        
        print(f"âœ… No thread leaks: {thread_growth:+d} threads after 100 files")


class TestLongRunningStability:
    """Test long-running stability (abbreviated for unit tests)"""
    
    @pytest.mark.slow
    def test_high_volume_processing(self, leak_dirs, mock_wats_client, process_monitor):
        """
        STABILITY: Process 500 files continuously
        EXPECTED: Stable memory, no crashes, all files processed
        """
        converter = LeakTestConverter()
        converter.config = ConverterConfig(
            name="LeakTestConverter",
            module_path="test.leak",
            watch_folder=str(leak_dirs['watch']),
            done_folder=str(leak_dirs['done']),
            enabled=True,
            priority=5,
        )
        
        # Baseline metrics
        gc.collect()
        baseline_memory = process_monitor.memory_info().rss / 1024 / 1024
        
        # Process 500 files (reduced for faster testing)
        file_count = 500
        memory_samples = []
        
        start = time.perf_counter()
        
        for i in range(file_count):
            test_file = TestFileGenerator.generate_csv_file(
                leak_dirs['watch'] / f"file_{i:04d}.csv",
                rows=5
            )
            
            converter.convert_file(test_file, ConverterArguments(
                api_client=mock_wats_client,
                file_info=FileInfo(path=test_file),
                drop_folder=leak_dirs['watch'],
                done_folder=leak_dirs['done'],
                error_folder=leak_dirs['error'],
            ))
            
            # Sample every 100 files
            if i % 100 == 0:
                gc.collect()
                current_memory = process_monitor.memory_info().rss / 1024 / 1024
                memory_samples.append((i, current_memory))
        
        elapsed = time.perf_counter() - start
        
        # Final metrics
        gc.collect()
        final_memory = process_monitor.memory_info().rss / 1024 / 1024
        memory_growth = final_memory - baseline_memory
        growth_percent = (memory_growth / baseline_memory) * 100
        throughput = file_count / elapsed
        
        print(f"\nðŸ“Š High-Volume Stability Test:")
        print(f"  Files: {file_count}")
        print(f"  Time: {elapsed:.2f}s")
        print(f"  Throughput: {throughput:.0f} files/s")
        print(f"  Baseline memory: {baseline_memory:.2f} MB")
        print(f"  Final memory: {final_memory:.2f} MB")
        print(f"  Growth: {memory_growth:+.2f} MB ({growth_percent:+.1f}%)")
        
        # Display memory samples
        print(f"\n  Memory progression:")
        for files_processed, mem in memory_samples:
            delta = mem - baseline_memory
            print(f"    {files_processed:5d} files: {mem:.2f} MB ({delta:+.2f} MB)")
        
        # Verify stability
        assert converter.conversion_count == file_count
        assert growth_percent < 15, f"Memory grew {growth_percent:.1f}% (>15% threshold)"
        assert throughput > 10, f"Throughput too low: {throughput:.0f} files/s"
        
        print(f"âœ… High-volume stability: {file_count} files, {growth_percent:.1f}% growth")


# ============================================================================
# SUMMARY
# ============================================================================
"""
MEMORY & RESOURCE LEAK TEST COVERAGE:
================================================================================

MEMORY LEAKS (2 tests):
  âœ“ Memory stable over 1000 conversions (<10% growth)
  âœ“ Memory released after batch processing (GC cleanup)

FILE HANDLE LEAKS (2 tests):
  âœ“ File handles stable over 500 open/close cycles (<20 handle growth)
  âœ“ All files closed properly (no locked files)

THREAD LEAKS (1 test):
  âœ“ No thread leaks after 100 conversions (0 thread growth)

LONG-RUNNING STABILITY (1 test):
  âœ“ High-volume processing (500 files, <15% memory growth)

TOTAL: 6 resource leak detection tests
FOCUS: Memory stability, file handle management, thread cleanup

All tests validate that resources are properly managed and released.
================================================================================
"""
